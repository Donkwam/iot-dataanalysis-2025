{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65dbff9a",
   "metadata": {},
   "source": [
    "## YOLO\n",
    "\n",
    "### PyTorch 기반 물체인식 모델\n",
    "- CNN, rCNN(Regions with CNN)\n",
    "- https://github.com/ultralytics/ultralytics 참조\n",
    "\n",
    "#### YOLOv5 이상 설치\n",
    "```shell\n",
    "> pip install ultralytics\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd98725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.109-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from ultralytics) (3.10.1)\n",
      "Collecting opencv-python>=4.6.0 (from ultralytics)\n",
      "  Downloading opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from ultralytics) (11.1.0)\n",
      "Collecting pyyaml>=5.3.1 (from ultralytics)\n",
      "  Downloading PyYAML-6.0.2-cp311-cp311-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from ultralytics) (1.15.2)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from ultralytics) (2.6.0+cu118)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from ultralytics) (0.21.0+cu118)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: psutil in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from ultralytics) (7.0.0)\n",
      "Collecting py-cpuinfo (from ultralytics)\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from ultralytics) (2.2.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from ultralytics) (0.13.2)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
      "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
      "Requirement already satisfied: filelock in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.13.1)\n",
      "Requirement already satisfied: networkx in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Downloading ultralytics-8.3.109-py3-none-any.whl (974 kB)\n",
      "   ---------------------------------------- 0.0/974.8 kB ? eta -:--:--\n",
      "   ------ --------------------------------- 163.8/974.8 kB 3.3 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 522.2/974.8 kB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  972.8/974.8 kB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 974.8/974.8 kB 6.1 MB/s eta 0:00:00\n",
      "Downloading opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl (39.5 MB)\n",
      "   ---------------------------------------- 0.0/39.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/39.5 MB 15.0 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 1.2/39.5 MB 15.5 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 2.0/39.5 MB 18.2 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 3.1/39.5 MB 20.0 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 4.4/39.5 MB 23.2 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 6.2/39.5 MB 26.5 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 8.7/39.5 MB 30.8 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 11.2/39.5 MB 38.6 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 14.6/39.5 MB 50.4 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 17.5/39.5 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 21.6/39.5 MB 81.8 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 24.9/39.5 MB 72.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 28.5/39.5 MB 81.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 32.7/39.5 MB 81.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 36.2/39.5 MB 81.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.0/39.5 MB 93.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.5/39.5 MB 81.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 39.5/39.5 MB 50.1 MB/s eta 0:00:00\n",
      "Downloading PyYAML-6.0.2-cp311-cp311-win_amd64.whl (161 kB)\n",
      "   ---------------------------------------- 0.0/162.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 162.0/162.0 kB ? eta 0:00:00\n",
      "Downloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
      "Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: py-cpuinfo, pyyaml, opencv-python, ultralytics-thop, ultralytics\n",
      "Successfully installed opencv-python-4.11.0.86 py-cpuinfo-9.0.0 pyyaml-6.0.2 ultralytics-8.3.109 ultralytics-thop-2.0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# YOLO 설치\n",
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b4643c",
   "metadata": {},
   "source": [
    "#### 콘솔에서 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "152ebf9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.109 🚀 Python-3.11.9 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce GTX 1650, 4096MiB)\n",
      "YOLO11n summary (fused): 100 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n",
      "\n",
      "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
      "image 1/1 c:\\Source\\iot-dataanalysis-2025\\day08\\bus.jpg: 640x480 4 persons, 1 bus, 31.3ms\n",
      "Speed: 2.7ms preprocess, 31.3ms inference, 75.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1mC:\\Source\\iot-dataanalysis-2025\\runs\\detect\\predict2\u001b[0m\n",
      "💡 Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    }
   ],
   "source": [
    "# 콘솔에서 예측\n",
    "## yolo11n.pt - pretrained YOLO model\n",
    "## 자동으로 yolo11n.pt 다운로드\n",
    "## 웹 URL에 있는 이미지도 예측이 가능\n",
    "!yolo predict model=yolo11n.pt source='https://ultralytics.com/images/bus.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b92f25",
   "metadata": {},
   "source": [
    "#### 파이썬으로 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36a00bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLO 모듈 로드\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f96fdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLO 클래스가 들어오는 모델의 버전에 따라 알아서 YOLO 예측모델 객체 생성\n",
    "model = YOLO('./yolo11n.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1e8b29",
   "metadata": {},
   "source": [
    "##### coco8.yaml\n",
    "- https://github.com/ultralytics/assets/releases/download/v0.0.0/coco8.zip\n",
    "- 위 내용대로 훈련을 시킨 결과 -> yolo11n.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0942d757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.109  Python-3.11.9 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce GTX 1650, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=./yolo11n.pt, data=./coco8.yaml, epochs=100, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cuda:0, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=C:\\Source\\iot-dataanalysis-2025\\runs\\detect\\train2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    464912  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
      "YOLO11n summary: 181 layers, 2,624,080 parameters, 2,624,064 gradients, 6.6 GFLOPs\n",
      "\n",
      "Transferred 94/499 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir C:\\Source\\iot-dataanalysis-2025\\runs\\detect\\train2', view at http://localhost:6006/\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks failed . AMP training on NVIDIA GeForce GTX 1650 GPU may cause NaN losses or zero-mAP results, so AMP will be disabled during training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Source\\datasets\\coco8\\labels\\train.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Source\\datasets\\coco8\\labels\\val... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<00:00, 800.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Source\\datasets\\coco8\\labels\\val.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to C:\\Source\\iot-dataanalysis-2025\\runs\\detect\\train2\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Source\\iot-dataanalysis-2025\\runs\\detect\\train2\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/100      1.25G      2.707      5.611      2.738         21        640: 100%|██████████| 1/1 [00:08<00:00,  8.67s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  7.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/100      1.28G      2.786      5.149       2.93         36        640: 100%|██████████| 1/1 [00:00<00:00,  4.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17    0.00014     0.0167   8.62e-05   8.62e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/100      1.29G      2.833      5.716      2.677         20        640: 100%|██████████| 1/1 [00:00<00:00,  4.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17    0.00057     0.0667   0.000839    0.00013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/100      1.31G      2.705       5.44      2.643         21        640: 100%|██████████| 1/1 [00:00<00:00,  4.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 13.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.173     0.0167     0.0084    0.00411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/100      1.32G      3.269      5.756      3.056         19        640: 100%|██████████| 1/1 [00:00<00:00,  4.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 13.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.172     0.0167    0.00535    0.00321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/100      1.33G      2.752      5.576      2.721         22        640: 100%|██████████| 1/1 [00:00<00:00,  4.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 13.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000173     0.0167    0.00536    0.00321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/100      1.35G      2.938      5.703      2.871         20        640: 100%|██████████| 1/1 [00:00<00:00,  4.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000292     0.0167    0.00157   0.000786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/100      1.37G      3.301      5.599      3.221         20        640: 100%|██████████| 1/1 [00:00<00:00,  4.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 13.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000333     0.0167   0.000871   0.000429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/100      1.38G      2.948      5.656      2.861         20        640: 100%|██████████| 1/1 [00:00<00:00,  4.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 13.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000347     0.0167    0.00109   0.000467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/100      1.39G      2.741      5.278      2.778         25        640: 100%|██████████| 1/1 [00:00<00:00,  4.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 13.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000361     0.0167   0.000918   0.000416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/100      1.41G       2.59      5.195      2.738         31        640: 100%|██████████| 1/1 [00:00<00:00,  4.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 13.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000373     0.0167   0.000756   0.000386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/100      1.42G      2.944      5.289      2.869         31        640: 100%|██████████| 1/1 [00:00<00:00,  4.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 13.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000333     0.0167   0.000871   0.000464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/100      1.44G      3.041      5.318       3.16         24        640: 100%|██████████| 1/1 [00:00<00:00,  4.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 13.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000343     0.0167    0.00148   0.000633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/100      1.45G      2.735      5.911      2.926         15        640: 100%|██████████| 1/1 [00:00<00:00,  4.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 13.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000332     0.0167    0.00114   0.000519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/100      1.47G      2.695      5.048      2.888         38        640: 100%|██████████| 1/1 [00:00<00:00,  4.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 13.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000327     0.0167   0.000903   0.000444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/100      1.48G      2.908      5.115      2.673         49        640: 100%|██████████| 1/1 [00:00<00:00,  4.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 13.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17     0.0003     0.0167   0.000576   0.000337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/100       1.5G      2.591      5.408      2.741         25        640: 100%|██████████| 1/1 [00:00<00:00,  4.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000282     0.0167   0.000439   0.000285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/100      1.52G      2.912      5.614      2.645         16        640: 100%|██████████| 1/1 [00:00<00:00,  5.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 13.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000282     0.0167   0.000439   0.000285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/100      1.54G      2.603       5.18      2.585         34        640: 100%|██████████| 1/1 [00:00<00:00,  4.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 13.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000227     0.0167   0.000343   0.000172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     20/100      1.54G      2.663      5.606      2.586         25        640: 100%|██████████| 1/1 [00:00<00:00,  5.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000227     0.0167   0.000343   0.000172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     21/100      1.57G      2.596      5.328      2.748         26        640: 100%|██████████| 1/1 [00:00<00:00,  4.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 13.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000223     0.0167   0.000366   0.000143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     22/100      1.57G      2.739      5.068      2.542         52        640: 100%|██████████| 1/1 [00:00<00:00,  5.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 13.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000223     0.0167   0.000366   0.000143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     23/100       1.6G      2.761      5.474      2.781         22        640: 100%|██████████| 1/1 [00:00<00:00,  4.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 13.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000402     0.0333   0.000481   0.000169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     24/100      1.61G      2.754      5.175       2.79         34        640: 100%|██████████| 1/1 [00:00<00:00,  5.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000402     0.0333   0.000481   0.000169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     25/100      1.63G      3.358      6.392      3.234         11        640: 100%|██████████| 1/1 [00:00<00:00,  4.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 13.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000366     0.0333   0.000568   0.000181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     26/100      1.63G      2.959      5.204       2.79         35        640: 100%|██████████| 1/1 [00:00<00:00,  5.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 13.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000366     0.0333   0.000568   0.000181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     27/100      1.66G      2.723      5.268      2.687         24        640: 100%|██████████| 1/1 [00:00<00:00,  4.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000346     0.0333   0.000564   0.000137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     28/100      1.66G      2.686      5.259      2.648         35        640: 100%|██████████| 1/1 [00:00<00:00,  5.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 13.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000346     0.0333   0.000564   0.000137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     29/100      1.69G      3.191      5.479      2.889         28        640: 100%|██████████| 1/1 [00:00<00:00,  4.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17    0.00051       0.05    0.00067    0.00018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     30/100      1.69G      2.717      5.398      2.876         29        640: 100%|██████████| 1/1 [00:00<00:00,  5.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 13.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17    0.00051       0.05    0.00067    0.00018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     31/100      1.72G       3.14      5.505      3.045         25        640: 100%|██████████| 1/1 [00:00<00:00,  4.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 13.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000494       0.05   0.000596   0.000125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     32/100      1.72G      2.728      5.442        2.8         20        640: 100%|██████████| 1/1 [00:00<00:00,  5.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 13.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000494       0.05   0.000596   0.000125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     33/100      1.75G      2.745      5.377      2.865         31        640: 100%|██████████| 1/1 [00:00<00:00,  4.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17    0.00049       0.05   0.000502   0.000112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     34/100      1.75G      2.689      5.079      2.795         32        640: 100%|██████████| 1/1 [00:00<00:00,  5.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 13.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17    0.00049       0.05   0.000502   0.000112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     35/100      1.78G      2.676      5.524      2.786         23        640: 100%|██████████| 1/1 [00:00<00:00,  4.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000486       0.05   0.000456   0.000106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     36/100      1.79G      2.688      5.235      2.861         34        640: 100%|██████████| 1/1 [00:00<00:00,  5.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 13.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000486       0.05   0.000456   0.000106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     37/100      1.81G      2.794      5.025       2.54         34        640: 100%|██████████| 1/1 [00:00<00:00,  4.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000481       0.05   0.000429   8.59e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     38/100      1.81G      2.374      5.218      2.325         29        640: 100%|██████████| 1/1 [00:00<00:00,  5.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 13.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000481       0.05   0.000429   8.59e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     39/100      1.84G      2.602      5.336      2.652         25        640: 100%|██████████| 1/1 [00:00<00:00,  4.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 13.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000636     0.0667   0.000636   0.000142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     40/100      1.84G      2.549      5.513      2.549         19        640: 100%|██████████| 1/1 [00:00<00:00,  5.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000636     0.0667   0.000636   0.000142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     41/100      1.87G      2.757      5.486      2.699         29        640: 100%|██████████| 1/1 [00:00<00:00,  4.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000633     0.0667   0.000628    0.00015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     42/100      1.87G       2.56      5.253      2.549         34        640: 100%|██████████| 1/1 [00:00<00:00,  5.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000633     0.0667   0.000628    0.00015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     43/100       1.9G      2.774      5.335        2.8         20        640: 100%|██████████| 1/1 [00:00<00:00,  4.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 13.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000633     0.0667    0.00062   0.000189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     44/100       1.9G      2.801      5.437      2.847         23        640: 100%|██████████| 1/1 [00:00<00:00,  5.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 13.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000633     0.0667    0.00062   0.000189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     45/100      1.93G      2.501      4.875      2.558         40        640: 100%|██████████| 1/1 [00:00<00:00,  4.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 13.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000632     0.0667   0.000968   0.000251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     46/100      1.93G      2.312      5.242      2.633         23        640: 100%|██████████| 1/1 [00:00<00:00,  5.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000632     0.0667   0.000968   0.000251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     47/100      1.96G      2.845      5.688      2.827         14        640: 100%|██████████| 1/1 [00:00<00:00,  4.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000626     0.0667    0.00107   0.000317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     48/100      1.96G      2.438      5.271      2.672         31        640: 100%|██████████| 1/1 [00:00<00:00,  5.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000626     0.0667    0.00107   0.000317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     49/100      1.99G      2.534      5.493       2.56         17        640: 100%|██████████| 1/1 [00:00<00:00,  4.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000624     0.0667    0.00103   0.000401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     50/100      1.99G      2.487      5.057      2.586         31        640: 100%|██████████| 1/1 [00:00<00:00,  5.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000624     0.0667    0.00103   0.000401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     51/100      2.02G      2.709      5.009       2.69         35        640: 100%|██████████| 1/1 [00:00<00:00,  4.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 13.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000625     0.0667    0.00116   0.000459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x000001F7456789A0>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Source\\iot-dataanalysis-2025\\mlvenv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"c:\\Source\\iot-dataanalysis-2025\\mlvenv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1576, in _shutdown_workers\n",
      "    if self._persistent_workers or self._workers_status[worker_id]:\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute '_workers_status'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     52/100      1.23G      2.604      4.931      2.589         55        640: 100%|██████████| 1/1 [00:00<00:00,  5.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 13.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000625     0.0667    0.00116   0.000459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     53/100      1.25G      2.504      5.454      2.605         14        640: 100%|██████████| 1/1 [00:00<00:00,  5.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 13.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000625     0.0667    0.00116   0.000459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     54/100      1.27G      2.436      4.946      2.532         46        640: 100%|██████████| 1/1 [00:00<00:00,  4.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000619     0.0667    0.00129   0.000507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     55/100      1.27G      2.513      5.022      2.767         30        640: 100%|██████████| 1/1 [00:00<00:00,  5.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000619     0.0667    0.00129   0.000507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     56/100      1.29G      2.591      5.005      2.623         22        640: 100%|██████████| 1/1 [00:00<00:00,  5.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000619     0.0667    0.00129   0.000507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     57/100      1.31G      2.387      5.174      2.504         28        640: 100%|██████████| 1/1 [00:00<00:00,  4.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000617     0.0667    0.00158    0.00067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     58/100      1.32G      3.011      6.391        2.9         11        640: 100%|██████████| 1/1 [00:00<00:00,  5.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 13.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000617     0.0667    0.00158    0.00067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     59/100      1.34G      2.445      5.513      2.666         16        640: 100%|██████████| 1/1 [00:00<00:00,  5.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 13.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000617     0.0667    0.00158    0.00067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     60/100      1.36G      2.419       4.96      2.631         30        640: 100%|██████████| 1/1 [00:00<00:00,  4.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 13.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000622     0.0667    0.00175   0.000577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     61/100      1.36G      2.824      5.315      2.749         26        640: 100%|██████████| 1/1 [00:00<00:00,  5.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 13.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000622     0.0667    0.00175   0.000577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     62/100      1.39G      2.649      5.351      2.714         20        640: 100%|██████████| 1/1 [00:00<00:00,  5.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000622     0.0667    0.00175   0.000577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     63/100       1.4G      2.447      5.518      2.408         16        640: 100%|██████████| 1/1 [00:00<00:00,  4.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000626     0.0667    0.00187   0.000649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     64/100       1.4G      2.241      5.246      2.345         26        640: 100%|██████████| 1/1 [00:00<00:00,  5.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000626     0.0667    0.00187   0.000649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     65/100      1.43G      2.432      5.093      2.468         37        640: 100%|██████████| 1/1 [00:00<00:00,  5.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000626     0.0667    0.00187   0.000649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     66/100      1.45G      2.599          5      2.822         51        640: 100%|██████████| 1/1 [00:00<00:00,  4.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000626     0.0667    0.00189   0.000759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     67/100      1.45G      2.328      4.941      2.455         37        640: 100%|██████████| 1/1 [00:00<00:00,  5.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 13.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000626     0.0667    0.00189   0.000759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     68/100      1.47G      2.574      5.179      2.434         31        640: 100%|██████████| 1/1 [00:00<00:00,  5.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000626     0.0667    0.00189   0.000759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     69/100      1.49G       2.67       5.72      2.738         12        640: 100%|██████████| 1/1 [00:00<00:00,  4.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17    0.00063     0.0667    0.00202   0.000677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     70/100       1.5G      2.572       6.39      2.535          9        640: 100%|██████████| 1/1 [00:00<00:00,  5.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17    0.00063     0.0667    0.00202   0.000677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     71/100      1.52G      2.514      5.147      2.457         23        640: 100%|██████████| 1/1 [00:00<00:00,  5.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17    0.00063     0.0667    0.00202   0.000677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     72/100      1.54G      2.161      5.285      2.446         21        640: 100%|██████████| 1/1 [00:00<00:00,  4.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000634     0.0667    0.00201   0.000723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     73/100      1.54G      2.178      5.405      2.634         15        640: 100%|██████████| 1/1 [00:00<00:00,  5.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000634     0.0667    0.00201   0.000723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     74/100      1.56G      2.966      5.162      2.909         28        640: 100%|██████████| 1/1 [00:00<00:00,  5.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000634     0.0667    0.00201   0.000723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     75/100      1.58G      2.535      4.986      2.338         60        640: 100%|██████████| 1/1 [00:00<00:00,  4.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17    0.00048       0.05    0.00184    0.00071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     76/100      1.58G      2.267      5.349      2.537         14        640: 100%|██████████| 1/1 [00:00<00:00,  5.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17    0.00048       0.05    0.00184    0.00071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     77/100      1.61G      2.325       4.88      2.445         37        640: 100%|██████████| 1/1 [00:00<00:00,  5.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17    0.00048       0.05    0.00184    0.00071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     78/100      1.62G      2.408      4.829      2.492         45        640: 100%|██████████| 1/1 [00:00<00:00,  4.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000484       0.05    0.00157   0.000602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     79/100      1.63G      2.879      5.713      2.801         16        640: 100%|██████████| 1/1 [00:00<00:00,  5.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000484       0.05    0.00157   0.000602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     80/100      1.66G      2.608      5.184      2.621         21        640: 100%|██████████| 1/1 [00:00<00:00,  5.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000484       0.05    0.00157   0.000602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     81/100      1.67G      2.462      4.893      2.433         42        640: 100%|██████████| 1/1 [00:00<00:00,  4.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000485       0.05    0.00148   0.000558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     82/100      1.68G      1.875      4.946      2.178         32        640: 100%|██████████| 1/1 [00:00<00:00,  5.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000485       0.05    0.00148   0.000558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     83/100       1.7G      2.481      5.196      2.411         31        640: 100%|██████████| 1/1 [00:00<00:00,  5.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000485       0.05    0.00148   0.000558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     84/100      1.71G      2.531      4.859      2.789         30        640: 100%|██████████| 1/1 [00:00<00:00,  4.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000487       0.05    0.00124   0.000465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     85/100      1.72G      2.337      4.903      2.485         26        640: 100%|██████████| 1/1 [00:00<00:00,  5.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000487       0.05    0.00124   0.000465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     86/100      1.74G      2.401       4.97       2.61         24        640: 100%|██████████| 1/1 [00:00<00:00,  5.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 13.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000487       0.05    0.00124   0.000465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     87/100      1.76G      2.058       4.85       2.34         31        640: 100%|██████████| 1/1 [00:00<00:00,  5.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000487       0.05    0.00124   0.000465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     88/100      1.78G      2.686      4.979      2.652         47        640: 100%|██████████| 1/1 [00:00<00:00,  4.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000488       0.05    0.00111   0.000338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     89/100      1.78G      2.404      5.095      2.626         26        640: 100%|██████████| 1/1 [00:00<00:00,  5.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000488       0.05    0.00111   0.000338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     90/100       1.8G      2.473       5.13       2.37         31        640: 100%|██████████| 1/1 [00:00<00:00,  5.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000488       0.05    0.00111   0.000338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     91/100      1.82G      2.115      5.509      2.446         13        640: 100%|██████████| 1/1 [00:06<00:00,  6.20s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000488       0.05    0.00111   0.000338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     92/100      1.83G      2.141       5.33      2.302         13        640: 100%|██████████| 1/1 [00:00<00:00,  4.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000491       0.05    0.00131   0.000336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     93/100      1.84G      1.826      5.205      2.293         13        640: 100%|██████████| 1/1 [00:00<00:00,  5.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000491       0.05    0.00131   0.000336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     94/100      1.86G      2.163      5.374      2.488         13        640: 100%|██████████| 1/1 [00:00<00:00,  5.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 13.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000491       0.05    0.00131   0.000336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     95/100      1.88G      2.145      5.327      2.478         13        640: 100%|██████████| 1/1 [00:00<00:00,  5.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000491       0.05    0.00131   0.000336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     96/100      1.89G      2.363        5.7       2.67         13        640: 100%|██████████| 1/1 [00:00<00:00,  4.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000498       0.05   0.000955    0.00026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     97/100       1.9G      2.164      5.538      2.419         13        640: 100%|██████████| 1/1 [00:00<00:00,  5.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000498       0.05   0.000955    0.00026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     98/100      1.92G      2.224      5.249      2.602         13        640: 100%|██████████| 1/1 [00:00<00:00,  5.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000498       0.05   0.000955    0.00026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     99/100      1.94G      2.285      5.547      2.629         13        640: 100%|██████████| 1/1 [00:00<00:00,  5.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000498       0.05   0.000955    0.00026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    100/100      1.95G      2.084      5.293      2.398         13        640: 100%|██████████| 1/1 [00:00<00:00,  4.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 13.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17   0.000501       0.05   0.000759   0.000223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "100 epochs completed in 0.024 hours.\n",
      "Optimizer stripped from C:\\Source\\iot-dataanalysis-2025\\runs\\detect\\train2\\weights\\last.pt, 5.5MB\n",
      "Optimizer stripped from C:\\Source\\iot-dataanalysis-2025\\runs\\detect\\train2\\weights\\best.pt, 5.5MB\n",
      "\n",
      "Validating C:\\Source\\iot-dataanalysis-2025\\runs\\detect\\train2\\weights\\best.pt...\n",
      "Ultralytics 8.3.109  Python-3.11.9 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce GTX 1650, 4096MiB)\n",
      "YOLO11n summary (fused): 100 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 16.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.173     0.0167     0.0084    0.00411\n",
      "                person          3         10     0.0386        0.1     0.0504     0.0247\n",
      "                   dog          1          1          1          0          0          0\n",
      "                 horse          1          2          0          0          0          0\n",
      "              elephant          1          2          0          0          0          0\n",
      "              umbrella          1          1          0          0          0          0\n",
      "          potted plant          1          1          0          0          0          0\n",
      "Speed: 0.5ms preprocess, 9.1ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Source\\iot-dataanalysis-2025\\runs\\detect\\train2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# coco8.yaml - YOLO 훈련에 사용할 데이터셋 정의 파일\n",
    "train_results = model.train(\n",
    "    data = './coco8.yaml',\n",
    "    epochs = 100,\n",
    "    imgsz = 640,\n",
    "    device='cuda:0'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcc7fc9",
   "metadata": {},
   "source": [
    "#### 이미지 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d930fdc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Source\\iot-dataanalysis-2025\\day08\\0000001.jpg: 480x640 1 cat, 37.7ms\n",
      "Speed: 1.7ms preprocess, 37.7ms inference, 101.9ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "result = model('./0000001.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25328df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maptplotlib 모듈 로드\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw, ImageFont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8649a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = result[0].plot()\n",
    "img_pil = Image.fromarray(img[..., ::-1])\n",
    "img_pil.save('./predict_result.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa50a93e",
   "metadata": {},
   "source": [
    "### OpenCV\n",
    "- Opensource Computer Vision 약자. 실시간 컴퓨터 비전(시각처리)을 목적으로 프로그래밍 라이브러리\n",
    "- 인텔에서 2000년에 C, C++ 사용하기위해서 개발\n",
    "- 파이썬에서 사용할 수 있게 래핑\n",
    "\n",
    "```shell\n",
    "> pip install opencv-python\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db46b948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from opencv-python) (1.26.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# OpenCV 설치\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3385439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.11.0'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b15e671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(464, 640, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img2 = cv2.imread('./predict_result.jpg')\n",
    "img2.shape  # (464, 640, 3) -> (height, width, channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a7521f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 윈도우 창 오픈\n",
    "cv2.imshow('predict_result', img2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f167c1cb",
   "metadata": {},
   "source": [
    "#### YOLO 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb9d90ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 416x640 1 bottle, 1 cup, 1 bowl, 1 tv, 1 mouse, 1 book, 65.0ms\n",
      "Speed: 64.5ms preprocess, 65.0ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('./0000002.jpg')\n",
    "resized_img = cv2.resize(img,(640, 400))\n",
    "\n",
    "result = model(resized_img)\n",
    "plots = result[0].plot()\n",
    "\n",
    "cv2.imshow('predict_result', plots)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da153373",
   "metadata": {},
   "source": [
    "#### 동영상 플레이\n",
    "- 라즈베리파이에서 동일하게 사용가능\n",
    "- 라즈베리파이 웹캠 사용추천"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "22b42957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비디오 파일 경로\n",
    "video_path = './sample01.mp4'\n",
    "output_path = './sample01_output.mp4'\n",
    "count_path = './sample01_count.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5610e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동영상 플레이\n",
    "cap = cv2.VideoCapture(video_path)  # 0 -> 웹캠이나 카메라 설치된 번호\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "\n",
    "    cv2.imshow('Video_play', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):   # q버늩을 누르면\n",
    "        break\n",
    "\n",
    "cap.release()   # 비디오를 해제\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae10cb1",
   "metadata": {},
   "source": [
    "#### YOLO 실시간 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "85960f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시간 모듈 로드\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c00aa226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 train, 121.0ms\n",
      "Speed: 14.6ms preprocess, 121.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 11.9ms\n",
      "Speed: 2.0ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 11.3ms\n",
      "Speed: 2.3ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 11.5ms\n",
      "Speed: 2.3ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 11.5ms\n",
      "Speed: 1.3ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 12.1ms\n",
      "Speed: 1.3ms preprocess, 12.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 11.8ms\n",
      "Speed: 1.3ms preprocess, 11.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 11.7ms\n",
      "Speed: 1.3ms preprocess, 11.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 12.1ms\n",
      "Speed: 1.4ms preprocess, 12.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 11.2ms\n",
      "Speed: 1.4ms preprocess, 11.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 11.2ms\n",
      "Speed: 1.4ms preprocess, 11.2ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 11.1ms\n",
      "Speed: 1.4ms preprocess, 11.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 10.9ms\n",
      "Speed: 1.8ms preprocess, 10.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 10.7ms\n",
      "Speed: 1.5ms preprocess, 10.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 10.9ms\n",
      "Speed: 2.5ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 11.0ms\n",
      "Speed: 3.0ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 11.0ms\n",
      "Speed: 2.9ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 10.9ms\n",
      "Speed: 2.2ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 12.7ms\n",
      "Speed: 2.3ms preprocess, 12.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 12.2ms\n",
      "Speed: 2.5ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 11.2ms\n",
      "Speed: 2.5ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 11.1ms\n",
      "Speed: 1.3ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 11.5ms\n",
      "Speed: 1.4ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 12.1ms\n",
      "Speed: 1.7ms preprocess, 12.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 14.5ms\n",
      "Speed: 1.6ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 11.0ms\n",
      "Speed: 2.2ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 10.8ms\n",
      "Speed: 2.2ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 10.5ms\n",
      "Speed: 2.4ms preprocess, 10.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 10.7ms\n",
      "Speed: 1.8ms preprocess, 10.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 11.0ms\n",
      "Speed: 1.4ms preprocess, 11.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 12.4ms\n",
      "Speed: 1.4ms preprocess, 12.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 11.3ms\n",
      "Speed: 1.3ms preprocess, 11.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 10.6ms\n",
      "Speed: 1.6ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 10.6ms\n",
      "Speed: 2.3ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 11.1ms\n",
      "Speed: 2.4ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 11.2ms\n",
      "Speed: 1.3ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 11.1ms\n",
      "Speed: 1.3ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 10.9ms\n",
      "Speed: 1.3ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 14.2ms\n",
      "Speed: 1.3ms preprocess, 14.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 12.6ms\n",
      "Speed: 1.3ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 11.7ms\n",
      "Speed: 1.3ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 11.1ms\n",
      "Speed: 1.4ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 11.3ms\n",
      "Speed: 1.6ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 13.8ms\n",
      "Speed: 1.4ms preprocess, 13.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 10.4ms\n",
      "Speed: 1.4ms preprocess, 10.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 10.5ms\n",
      "Speed: 1.5ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 10.6ms\n",
      "Speed: 1.9ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 10.6ms\n",
      "Speed: 2.7ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 10.6ms\n",
      "Speed: 2.7ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 11.0ms\n",
      "Speed: 2.4ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 12.1ms\n",
      "Speed: 1.3ms preprocess, 12.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 10.8ms\n",
      "Speed: 1.6ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 10.7ms\n",
      "Speed: 1.3ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 11.0ms\n",
      "Speed: 1.4ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 12.6ms\n",
      "Speed: 1.3ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 13.1ms\n",
      "Speed: 1.5ms preprocess, 13.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 12.3ms\n",
      "Speed: 1.3ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 11.4ms\n",
      "Speed: 1.3ms preprocess, 11.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 10.5ms\n",
      "Speed: 1.3ms preprocess, 10.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 10.6ms\n",
      "Speed: 1.5ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 10.7ms\n",
      "Speed: 2.4ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 10.8ms\n",
      "Speed: 2.5ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 11.4ms\n",
      "Speed: 1.4ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 11.0ms\n",
      "Speed: 1.4ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 12.1ms\n",
      "Speed: 1.3ms preprocess, 12.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 11.4ms\n",
      "Speed: 1.3ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 10.9ms\n",
      "Speed: 1.3ms preprocess, 10.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 10.7ms\n",
      "Speed: 1.4ms preprocess, 10.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 10.6ms\n",
      "Speed: 2.3ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 10.6ms\n",
      "Speed: 2.8ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 10.6ms\n",
      "Speed: 2.4ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 15.0ms\n",
      "Speed: 3.3ms preprocess, 15.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 2 trains, 12.5ms\n",
      "Speed: 2.4ms preprocess, 12.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 11.9ms\n",
      "Speed: 2.5ms preprocess, 11.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 10.6ms\n",
      "Speed: 1.5ms preprocess, 10.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 10.5ms\n",
      "Speed: 1.4ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 12.4ms\n",
      "Speed: 2.3ms preprocess, 12.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 10.4ms\n",
      "Speed: 2.5ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 10.3ms\n",
      "Speed: 2.7ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 10.4ms\n",
      "Speed: 2.0ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 10.5ms\n",
      "Speed: 2.3ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 13.2ms\n",
      "Speed: 1.3ms preprocess, 13.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 10.7ms\n",
      "Speed: 1.5ms preprocess, 10.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 13.6ms\n",
      "Speed: 1.6ms preprocess, 13.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 10.1ms\n",
      "Speed: 1.5ms preprocess, 10.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 11.2ms\n",
      "Speed: 1.6ms preprocess, 11.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 10.9ms\n",
      "Speed: 1.7ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 toilet, 11.7ms\n",
      "Speed: 1.3ms preprocess, 11.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 12.5ms\n",
      "Speed: 1.3ms preprocess, 12.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 13.4ms\n",
      "Speed: 1.4ms preprocess, 13.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 11.2ms\n",
      "Speed: 2.0ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 12.4ms\n",
      "Speed: 1.5ms preprocess, 12.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 1 train, 12.6ms\n",
      "Speed: 1.3ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 11.7ms\n",
      "Speed: 1.4ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 10.8ms\n",
      "Speed: 1.4ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 11.2ms\n",
      "Speed: 1.4ms preprocess, 11.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 11.5ms\n",
      "Speed: 1.3ms preprocess, 11.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 10.4ms\n",
      "Speed: 1.4ms preprocess, 10.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 10.4ms\n",
      "Speed: 1.5ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 11.1ms\n",
      "Speed: 1.7ms preprocess, 11.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 11.1ms\n",
      "Speed: 1.7ms preprocess, 11.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 10.8ms\n",
      "Speed: 2.5ms preprocess, 10.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 11.4ms\n",
      "Speed: 1.7ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 10.8ms\n",
      "Speed: 1.4ms preprocess, 10.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 10.6ms\n",
      "Speed: 1.5ms preprocess, 10.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 12.5ms\n",
      "Speed: 1.5ms preprocess, 12.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 10.5ms\n",
      "Speed: 1.8ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 11.9ms\n",
      "Speed: 2.3ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 11.1ms\n",
      "Speed: 1.4ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 10.9ms\n",
      "Speed: 1.4ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 11.2ms\n",
      "Speed: 1.4ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 11.0ms\n",
      "Speed: 1.3ms preprocess, 11.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 10.6ms\n",
      "Speed: 1.4ms preprocess, 10.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 11.3ms\n",
      "Speed: 1.7ms preprocess, 11.3ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 1 truck, 11.0ms\n",
      "Speed: 1.4ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 1 truck, 13.3ms\n",
      "Speed: 1.6ms preprocess, 13.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 11.8ms\n",
      "Speed: 1.3ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 10.7ms\n",
      "Speed: 1.6ms preprocess, 10.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 11.8ms\n",
      "Speed: 1.3ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 10.8ms\n",
      "Speed: 1.3ms preprocess, 10.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 11.2ms\n",
      "Speed: 1.4ms preprocess, 11.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 1 traffic light, 12.0ms\n",
      "Speed: 1.4ms preprocess, 12.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 10.8ms\n",
      "Speed: 1.4ms preprocess, 10.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 10.5ms\n",
      "Speed: 1.6ms preprocess, 10.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 10.2ms\n",
      "Speed: 2.2ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 10.6ms\n",
      "Speed: 2.5ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 10.8ms\n",
      "Speed: 1.7ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 11.0ms\n",
      "Speed: 1.6ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 11.0ms\n",
      "Speed: 1.6ms preprocess, 11.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 12.0ms\n",
      "Speed: 1.4ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 11.5ms\n",
      "Speed: 1.4ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 11.1ms\n",
      "Speed: 1.4ms preprocess, 11.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 11.3ms\n",
      "Speed: 1.4ms preprocess, 11.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 11.2ms\n",
      "Speed: 1.5ms preprocess, 11.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 10.8ms\n",
      "Speed: 1.6ms preprocess, 10.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 10.8ms\n",
      "Speed: 2.8ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 11.4ms\n",
      "Speed: 1.3ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 11.0ms\n",
      "Speed: 1.5ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 11.5ms\n",
      "Speed: 1.4ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 11.1ms\n",
      "Speed: 1.4ms preprocess, 11.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 10.8ms\n",
      "Speed: 1.9ms preprocess, 10.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 10.7ms\n",
      "Speed: 1.6ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 10.6ms\n",
      "Speed: 3.1ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 11.3ms\n",
      "Speed: 2.2ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 12.3ms\n",
      "Speed: 1.6ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 11.2ms\n",
      "Speed: 1.4ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 1 train, 11.6ms\n",
      "Speed: 2.5ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 11.2ms\n",
      "Speed: 3.0ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 10.3ms\n",
      "Speed: 2.6ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 1 train, 11.0ms\n",
      "Speed: 2.2ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 1 train, 10.9ms\n",
      "Speed: 2.6ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 1 train, 10.5ms\n",
      "Speed: 1.8ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 1 train, 10.4ms\n",
      "Speed: 2.4ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 1 train, 11.7ms\n",
      "Speed: 1.5ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 11.0ms\n",
      "Speed: 2.1ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 11.3ms\n",
      "Speed: 1.6ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 11.3ms\n",
      "Speed: 1.5ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 12.1ms\n",
      "Speed: 2.8ms preprocess, 12.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 10.6ms\n",
      "Speed: 1.5ms preprocess, 10.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 10.9ms\n",
      "Speed: 1.6ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 1 train, 10.8ms\n",
      "Speed: 2.2ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 11.4ms\n",
      "Speed: 2.2ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 10.6ms\n",
      "Speed: 1.7ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 10.9ms\n",
      "Speed: 2.2ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 10.7ms\n",
      "Speed: 1.5ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 11.8ms\n",
      "Speed: 1.6ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 11.0ms\n",
      "Speed: 1.7ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 12.2ms\n",
      "Speed: 1.4ms preprocess, 12.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 11.5ms\n",
      "Speed: 1.7ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 11.0ms\n",
      "Speed: 1.5ms preprocess, 11.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 12.9ms\n",
      "Speed: 1.4ms preprocess, 12.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 11.6ms\n",
      "Speed: 1.4ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 12.7ms\n",
      "Speed: 1.5ms preprocess, 12.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 11.5ms\n",
      "Speed: 1.4ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 11.0ms\n",
      "Speed: 1.4ms preprocess, 11.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 10.6ms\n",
      "Speed: 1.4ms preprocess, 10.6ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 11.2ms\n",
      "Speed: 1.6ms preprocess, 11.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 12.2ms\n",
      "Speed: 1.4ms preprocess, 12.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 13.7ms\n",
      "Speed: 1.4ms preprocess, 13.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 11.6ms\n",
      "Speed: 3.0ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 11.9ms\n",
      "Speed: 1.4ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 10.9ms\n",
      "Speed: 1.8ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 10.9ms\n",
      "Speed: 2.2ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 10.8ms\n",
      "Speed: 1.5ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 11.2ms\n",
      "Speed: 1.4ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 11.6ms\n",
      "Speed: 1.5ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 11.6ms\n",
      "Speed: 1.4ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 11.7ms\n",
      "Speed: 1.3ms preprocess, 11.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 10.4ms\n",
      "Speed: 1.4ms preprocess, 10.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 11.5ms\n",
      "Speed: 1.4ms preprocess, 11.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 12.6ms\n",
      "Speed: 1.6ms preprocess, 12.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 12.3ms\n",
      "Speed: 1.5ms preprocess, 12.3ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 11.4ms\n",
      "Speed: 1.4ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 12.7ms\n",
      "Speed: 1.4ms preprocess, 12.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 11.6ms\n",
      "Speed: 1.5ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 10.9ms\n",
      "Speed: 1.5ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 13.8ms\n",
      "Speed: 1.5ms preprocess, 13.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 11.2ms\n",
      "Speed: 1.4ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 10.9ms\n",
      "Speed: 1.4ms preprocess, 10.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 11.3ms\n",
      "Speed: 1.5ms preprocess, 11.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 11.7ms\n",
      "Speed: 1.5ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 11.3ms\n",
      "Speed: 1.4ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 12.9ms\n",
      "Speed: 1.6ms preprocess, 12.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 11.8ms\n",
      "Speed: 1.3ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 1 train, 1 truck, 12.3ms\n",
      "Speed: 1.3ms preprocess, 12.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 11.6ms\n",
      "Speed: 1.5ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 11.8ms\n",
      "Speed: 1.8ms preprocess, 11.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 12.2ms\n",
      "Speed: 1.3ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 12.2ms\n",
      "Speed: 1.5ms preprocess, 12.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 11.5ms\n",
      "Speed: 1.4ms preprocess, 11.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 suitcase, 12.9ms\n",
      "Speed: 1.5ms preprocess, 12.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 11.9ms\n",
      "Speed: 1.5ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 14.1ms\n",
      "Speed: 1.5ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 11.6ms\n",
      "Speed: 1.4ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 10.5ms\n",
      "Speed: 1.4ms preprocess, 10.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 12.0ms\n",
      "Speed: 1.4ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 13.8ms\n",
      "Speed: 1.5ms preprocess, 13.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 11.0ms\n",
      "Speed: 1.8ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 11.9ms\n",
      "Speed: 1.4ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 1 truck, 13.6ms\n",
      "Speed: 1.4ms preprocess, 13.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 12.6ms\n",
      "Speed: 1.4ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 11.7ms\n",
      "Speed: 1.5ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 12.2ms\n",
      "Speed: 1.8ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 12.4ms\n",
      "Speed: 2.3ms preprocess, 12.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 10.6ms\n",
      "Speed: 2.5ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 11.2ms\n",
      "Speed: 1.4ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 12.2ms\n",
      "Speed: 1.5ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 12.5ms\n",
      "Speed: 1.3ms preprocess, 12.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 10.9ms\n",
      "Speed: 1.3ms preprocess, 10.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 11.0ms\n",
      "Speed: 1.4ms preprocess, 11.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 12.6ms\n",
      "Speed: 1.5ms preprocess, 12.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 12.3ms\n",
      "Speed: 1.6ms preprocess, 12.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 11.6ms\n",
      "Speed: 1.4ms preprocess, 11.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 13.2ms\n",
      "Speed: 1.5ms preprocess, 13.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 11.5ms\n",
      "Speed: 1.3ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 14.7ms\n",
      "Speed: 1.3ms preprocess, 14.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 11.4ms\n",
      "Speed: 1.3ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 12.0ms\n",
      "Speed: 1.3ms preprocess, 12.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 10.1ms\n",
      "Speed: 1.5ms preprocess, 10.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 11.9ms\n",
      "Speed: 1.9ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 11.2ms\n",
      "Speed: 1.5ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 11.6ms\n",
      "Speed: 1.5ms preprocess, 11.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 12.7ms\n",
      "Speed: 1.5ms preprocess, 12.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 11.9ms\n",
      "Speed: 1.4ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 12.0ms\n",
      "Speed: 1.3ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 10.4ms\n",
      "Speed: 1.4ms preprocess, 10.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 10.4ms\n",
      "Speed: 1.4ms preprocess, 10.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 11.7ms\n",
      "Speed: 2.8ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 10.1ms\n",
      "Speed: 2.3ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 11.8ms\n",
      "Speed: 2.4ms preprocess, 11.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 11.1ms\n",
      "Speed: 2.3ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 1 train, 10.3ms\n",
      "Speed: 1.9ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 12.7ms\n",
      "Speed: 2.0ms preprocess, 12.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 13.1ms\n",
      "Speed: 1.6ms preprocess, 13.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 10.9ms\n",
      "Speed: 1.5ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 11.0ms\n",
      "Speed: 1.4ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 11.8ms\n",
      "Speed: 1.3ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 10.2ms\n",
      "Speed: 1.4ms preprocess, 10.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 10.0ms\n",
      "Speed: 1.5ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 10.1ms\n",
      "Speed: 1.6ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 13.7ms\n",
      "Speed: 1.4ms preprocess, 13.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 10.5ms\n",
      "Speed: 1.3ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 12.9ms\n",
      "Speed: 1.3ms preprocess, 12.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 10.2ms\n",
      "Speed: 1.3ms preprocess, 10.2ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 10.2ms\n",
      "Speed: 1.9ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 12.1ms\n",
      "Speed: 2.4ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 10.5ms\n",
      "Speed: 2.3ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 11.9ms\n",
      "Speed: 1.4ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 11.3ms\n",
      "Speed: 1.3ms preprocess, 11.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS) # 동영상 FPS(Frame Per Second)\n",
    "frame_time = 1.0 / fps  # 초단위로 변환\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))      # 1280\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))    # 720\n",
    "\n",
    "# VideoWriter 객체 생성(동영상 화면에 그림, 글자를 그리기 위한 객체)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "while cap.isOpened():\n",
    "    start_time = time.time()    # 시작시간\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "\n",
    "    # 객체 탐지\n",
    "    results = model(frame)\n",
    "    # 탐지 결과 그리기\n",
    "    for result in results:\n",
    "        detect_frame = result.plot()\n",
    "    # 결과프레임을 파일로 저장\n",
    "    out.write(detect_frame)\n",
    "    # 결과 표시\n",
    "    cv2.imshow('YOLO Object Derection', detect_frame)\n",
    "    cv2.imshow('Video play', frame)\n",
    "\n",
    "    # 프레임간 실제 지연시간 계산\n",
    "    elapsed_time = time.time() - start_time\n",
    "    delay = max(int((frame_time - elapsed_time) * 1000), 1)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):   # q버늩을 누르면\n",
    "        break\n",
    "\n",
    "cap.release()   # 비디오를 해제\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4d4229",
   "metadata": {},
   "source": [
    "#### Car Counting\n",
    "- 지정된 라인 아래로 내려오는 자동차 개수 카운팅"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225f5091",
   "metadata": {},
   "source": [
    "- shapely설치\n",
    "\n",
    "```shell\n",
    "> pip install shapely==2.0.1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "09f8db77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shapely==2.0.1 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: numpy>=1.14 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from shapely==2.0.1) (1.26.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# shapely 설치\n",
    "!pip install shapely==2.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f0e1e65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lap\n",
      "  Downloading lap-0.5.12-cp311-cp311-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.21.6 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from lap) (1.26.4)\n",
      "Downloading lap-0.5.12-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.2/1.5 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 0.7/1.5 MB 6.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.4/1.5 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 8.5 MB/s eta 0:00:00\n",
      "Installing collected packages: lap\n",
      "Successfully installed lap-0.5.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# lap 설치\n",
    "!pip install lap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1487bb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9392c2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics Solutions:  {'region': [(20, 400), (1080, 400)], 'show_in': True, 'show_out': True, 'colormap': None, 'up_angle': 145.0, 'down_angle': 90, 'kpts': [6, 8, 10], 'analytics_type': 'line', 'json_file': None, 'records': 5, 'show': True, 'model': './yolo11n.pt', 'line_width': 3}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 train, 11.7ms\n",
      "Speed: 2.0ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 train, 11.4ms\n",
      "Speed: 2.5ms preprocess, 11.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 train, 11.5ms\n",
      "Speed: 1.2ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 train, 12.9ms\n",
      "Speed: 1.3ms preprocess, 12.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 train, 10.6ms\n",
      "Speed: 2.9ms preprocess, 10.6ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 train, 10.9ms\n",
      "Speed: 1.6ms preprocess, 10.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 train, 11.7ms\n",
      "Speed: 2.3ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 train, 14.7ms\n",
      "Speed: 1.3ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 train, 12.3ms\n",
      "Speed: 1.4ms preprocess, 12.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 train, 11.1ms\n",
      "Speed: 1.6ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 train, 13.5ms\n",
      "Speed: 1.5ms preprocess, 13.5ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 10.8ms\n",
      "Speed: 2.4ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 10.8ms\n",
      "Speed: 2.7ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 10.6ms\n",
      "Speed: 2.3ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 12.8ms\n",
      "Speed: 1.3ms preprocess, 12.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 11.1ms\n",
      "Speed: 1.4ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 11.1ms\n",
      "Speed: 1.3ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 10.8ms\n",
      "Speed: 1.2ms preprocess, 10.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 10.6ms\n",
      "Speed: 1.6ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 11.5ms\n",
      "Speed: 1.3ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 10.8ms\n",
      "Speed: 1.5ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 12.4ms\n",
      "Speed: 1.3ms preprocess, 12.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 11.2ms\n",
      "Speed: 1.3ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 10.6ms\n",
      "Speed: 1.3ms preprocess, 10.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 13.7ms\n",
      "Speed: 1.3ms preprocess, 13.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 11.4ms\n",
      "Speed: 1.3ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 11.1ms\n",
      "Speed: 1.3ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 12.0ms\n",
      "Speed: 1.3ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 11.2ms\n",
      "Speed: 1.3ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 11.1ms\n",
      "Speed: 1.3ms preprocess, 11.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 10.5ms\n",
      "Speed: 1.6ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 12.0ms\n",
      "Speed: 1.3ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 11.0ms\n",
      "Speed: 1.3ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 12.4ms\n",
      "Speed: 1.3ms preprocess, 12.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 10.8ms\n",
      "Speed: 1.2ms preprocess, 10.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 10.5ms\n",
      "Speed: 1.7ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 11.3ms\n",
      "Speed: 1.3ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 11.0ms\n",
      "Speed: 1.4ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 11.9ms\n",
      "Speed: 1.4ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 14.1ms\n",
      "Speed: 1.4ms preprocess, 14.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 20.1ms\n",
      "Speed: 2.0ms preprocess, 20.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 19.7ms\n",
      "Speed: 2.3ms preprocess, 19.7ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 22.2ms\n",
      "Speed: 1.9ms preprocess, 22.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 10.9ms\n",
      "Speed: 1.6ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 11.3ms\n",
      "Speed: 2.4ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 10.6ms\n",
      "Speed: 2.1ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 12.2ms\n",
      "Speed: 1.5ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 4 cars, 11.5ms\n",
      "Speed: 1.5ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 4 cars, 10.7ms\n",
      "Speed: 1.5ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 4 cars, 10.9ms\n",
      "Speed: 1.4ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 5 cars, 10.6ms\n",
      "Speed: 1.4ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 12.3ms\n",
      "Speed: 1.3ms preprocess, 12.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 6 cars, 12.3ms\n",
      "Speed: 1.3ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 12.3ms\n",
      "Speed: 1.4ms preprocess, 12.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 10.7ms\n",
      "Speed: 1.6ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 11.5ms\n",
      "Speed: 1.4ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 3 cars, 11.0ms\n",
      "Speed: 1.4ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 3 cars, 10.9ms\n",
      "Speed: 1.4ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 10.9ms\n",
      "Speed: 1.7ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 10.9ms\n",
      "Speed: 1.3ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 11.0ms\n",
      "Speed: 1.3ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 10.9ms\n",
      "Speed: 1.3ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 11.4ms\n",
      "Speed: 1.3ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 11.0ms\n",
      "Speed: 2.4ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 10.9ms\n",
      "Speed: 1.4ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 2 cars, 2 trains, 10.8ms\n",
      "Speed: 1.4ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 11.0ms\n",
      "Speed: 1.4ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 12.1ms\n",
      "Speed: 1.3ms preprocess, 12.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 11.0ms\n",
      "Speed: 1.3ms preprocess, 11.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 10.7ms\n",
      "Speed: 1.3ms preprocess, 10.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 10.4ms\n",
      "Speed: 1.6ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 11.4ms\n",
      "Speed: 1.3ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 3 cars, 2 trains, 10.7ms\n",
      "Speed: 1.4ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 11.5ms\n",
      "Speed: 1.3ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 11.7ms\n",
      "Speed: 1.4ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 10.8ms\n",
      "Speed: 1.5ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 10.6ms\n",
      "Speed: 1.3ms preprocess, 10.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 10.3ms\n",
      "Speed: 1.7ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 10.4ms\n",
      "Speed: 1.9ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 10.6ms\n",
      "Speed: 2.4ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 13.9ms\n",
      "Speed: 2.3ms preprocess, 13.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 20.7ms\n",
      "Speed: 2.2ms preprocess, 20.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 22.5ms\n",
      "Speed: 1.9ms preprocess, 22.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 21.1ms\n",
      "Speed: 1.9ms preprocess, 21.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 10.5ms\n",
      "Speed: 1.4ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 5 cars, 11.0ms\n",
      "Speed: 1.6ms preprocess, 11.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 10.9ms\n",
      "Speed: 1.3ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 toilet, 10.6ms\n",
      "Speed: 3.0ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 11.9ms\n",
      "Speed: 1.4ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 10.8ms\n",
      "Speed: 1.5ms preprocess, 10.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 10.9ms\n",
      "Speed: 1.3ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 10.4ms\n",
      "Speed: 1.7ms preprocess, 10.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 12.7ms\n",
      "Speed: 1.4ms preprocess, 12.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 10.6ms\n",
      "Speed: 1.4ms preprocess, 10.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 13.2ms\n",
      "Speed: 1.4ms preprocess, 13.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 10.7ms\n",
      "Speed: 1.3ms preprocess, 10.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 10.4ms\n",
      "Speed: 1.5ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 10.6ms\n",
      "Speed: 1.9ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 11.8ms\n",
      "Speed: 1.3ms preprocess, 11.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 10.7ms\n",
      "Speed: 1.4ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 11.3ms\n",
      "Speed: 1.7ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 11.0ms\n",
      "Speed: 2.3ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 10.7ms\n",
      "Speed: 1.3ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 11.9ms\n",
      "Speed: 1.3ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 11.4ms\n",
      "Speed: 1.6ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=4, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 4, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 10.7ms\n",
      "Speed: 1.4ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=4, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 4, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 10.1ms\n",
      "Speed: 1.5ms preprocess, 10.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 10.2ms\n",
      "Speed: 1.5ms preprocess, 10.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 10.8ms\n",
      "Speed: 1.4ms preprocess, 10.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 10.7ms\n",
      "Speed: 1.4ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 10.7ms\n",
      "Speed: 1.4ms preprocess, 10.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 10.5ms\n",
      "Speed: 1.3ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 2 cars, 2 trains, 10.4ms\n",
      "Speed: 1.4ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 2 cars, 2 trains, 10.4ms\n",
      "Speed: 1.4ms preprocess, 10.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 10.9ms\n",
      "Speed: 1.4ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 1 truck, 10.6ms\n",
      "Speed: 1.4ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 10.3ms\n",
      "Speed: 1.7ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 10.9ms\n",
      "Speed: 1.3ms preprocess, 10.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 10.5ms\n",
      "Speed: 1.6ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 10.5ms\n",
      "Speed: 1.3ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 11.2ms\n",
      "Speed: 1.4ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 1 traffic light, 11.7ms\n",
      "Speed: 1.4ms preprocess, 11.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 20.9ms\n",
      "Speed: 2.0ms preprocess, 20.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 23.7ms\n",
      "Speed: 1.9ms preprocess, 23.7ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 24.3ms\n",
      "Speed: 2.0ms preprocess, 24.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 20.9ms\n",
      "Speed: 1.9ms preprocess, 20.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 24.8ms\n",
      "Speed: 1.8ms preprocess, 24.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 20.6ms\n",
      "Speed: 2.0ms preprocess, 20.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 17.3ms\n",
      "Speed: 1.9ms preprocess, 17.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 11.0ms\n",
      "Speed: 1.3ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 12.7ms\n",
      "Speed: 1.4ms preprocess, 12.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 11.5ms\n",
      "Speed: 1.4ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 10.3ms\n",
      "Speed: 1.5ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 10.4ms\n",
      "Speed: 1.5ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 10.2ms\n",
      "Speed: 1.8ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 10.9ms\n",
      "Speed: 1.4ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 10.6ms\n",
      "Speed: 1.4ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 10.5ms\n",
      "Speed: 1.3ms preprocess, 10.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 10.3ms\n",
      "Speed: 1.8ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 10.6ms\n",
      "Speed: 1.3ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 train, 10.8ms\n",
      "Speed: 1.6ms preprocess, 10.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 train, 10.2ms\n",
      "Speed: 1.3ms preprocess, 10.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 9.9ms\n",
      "Speed: 2.2ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 10.8ms\n",
      "Speed: 1.4ms preprocess, 10.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 10.6ms\n",
      "Speed: 1.5ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 11.1ms\n",
      "Speed: 1.5ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 10.8ms\n",
      "Speed: 1.5ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 11.3ms\n",
      "Speed: 1.4ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 10.9ms\n",
      "Speed: 1.3ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 10.3ms\n",
      "Speed: 1.3ms preprocess, 10.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 10.3ms\n",
      "Speed: 1.5ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 10.4ms\n",
      "Speed: 2.8ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 12.5ms\n",
      "Speed: 1.5ms preprocess, 12.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 10.5ms\n",
      "Speed: 1.4ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 16.3ms\n",
      "Speed: 1.9ms preprocess, 16.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 10.4ms\n",
      "Speed: 1.4ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 10.7ms\n",
      "Speed: 1.3ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 10.5ms\n",
      "Speed: 1.4ms preprocess, 10.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 10.4ms\n",
      "Speed: 1.7ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 10.2ms\n",
      "Speed: 2.8ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 10.6ms\n",
      "Speed: 1.5ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 13.0ms\n",
      "Speed: 1.4ms preprocess, 13.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 12.7ms\n",
      "Speed: 1.4ms preprocess, 12.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 12.5ms\n",
      "Speed: 1.4ms preprocess, 12.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 10.4ms\n",
      "Speed: 1.4ms preprocess, 10.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 7 cars, 1 train, 10.4ms\n",
      "Speed: 1.4ms preprocess, 10.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 7 cars, 1 train, 20.6ms\n",
      "Speed: 2.2ms preprocess, 20.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 7 cars, 1 train, 24.6ms\n",
      "Speed: 1.9ms preprocess, 24.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 7 cars, 1 train, 24.9ms\n",
      "Speed: 1.9ms preprocess, 24.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 7 cars, 1 train, 20.1ms\n",
      "Speed: 2.1ms preprocess, 20.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 6 cars, 25.5ms\n",
      "Speed: 1.9ms preprocess, 25.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 23.0ms\n",
      "Speed: 1.9ms preprocess, 23.0ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 20.5ms\n",
      "Speed: 2.0ms preprocess, 20.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 8 cars, 10.9ms\n",
      "Speed: 1.5ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 8 cars, 11.0ms\n",
      "Speed: 1.6ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 8 cars, 10.8ms\n",
      "Speed: 1.7ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 8 cars, 10.4ms\n",
      "Speed: 1.5ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 8 cars, 12.6ms\n",
      "Speed: 1.3ms preprocess, 12.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 8 cars, 10.9ms\n",
      "Speed: 1.3ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 8 cars, 10.4ms\n",
      "Speed: 2.6ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 7 cars, 10.9ms\n",
      "Speed: 1.6ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 12.3ms\n",
      "Speed: 1.4ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 11.0ms\n",
      "Speed: 1.3ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 12.5ms\n",
      "Speed: 2.3ms preprocess, 12.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 11.1ms\n",
      "Speed: 1.4ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 8 cars, 10.8ms\n",
      "Speed: 1.4ms preprocess, 10.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 9 cars, 13.0ms\n",
      "Speed: 1.4ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 14.5ms\n",
      "Speed: 1.6ms preprocess, 14.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 11.5ms\n",
      "Speed: 1.5ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 10.9ms\n",
      "Speed: 1.4ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 13.1ms\n",
      "Speed: 1.3ms preprocess, 13.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=6, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 6, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 10.7ms\n",
      "Speed: 1.8ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=6, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 6, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 10.6ms\n",
      "Speed: 1.3ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=6, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 6, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 11.0ms\n",
      "Speed: 1.3ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=6, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 6, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 10.8ms\n",
      "Speed: 1.3ms preprocess, 10.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=6, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 6, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 11.0ms\n",
      "Speed: 1.3ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=6, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 6, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 8 cars, 10.4ms\n",
      "Speed: 1.3ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=7, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 7, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 8 cars, 11.3ms\n",
      "Speed: 1.3ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=7, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 7, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 7 cars, 10.5ms\n",
      "Speed: 1.4ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=7, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 7, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 10.4ms\n",
      "Speed: 1.4ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=7, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 7, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 6 cars, 11.1ms\n",
      "Speed: 1.4ms preprocess, 11.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=7, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 7, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 10.8ms\n",
      "Speed: 1.3ms preprocess, 10.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=7, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 7, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 7 cars, 12.4ms\n",
      "Speed: 1.3ms preprocess, 12.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=7, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 7, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 6 cars, 10.9ms\n",
      "Speed: 1.3ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=7, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 7, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 10.9ms\n",
      "Speed: 1.5ms preprocess, 10.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 10.5ms\n",
      "Speed: 1.5ms preprocess, 10.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 12.2ms\n",
      "Speed: 1.3ms preprocess, 12.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 10.6ms\n",
      "Speed: 1.3ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 10.6ms\n",
      "Speed: 1.6ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 11.0ms\n",
      "Speed: 1.5ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 suitcase, 24.3ms\n",
      "Speed: 1.9ms preprocess, 24.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 7 cars, 20.7ms\n",
      "Speed: 1.9ms preprocess, 20.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 21.2ms\n",
      "Speed: 2.3ms preprocess, 21.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 6 cars, 23.3ms\n",
      "Speed: 2.0ms preprocess, 23.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 7 cars, 21.1ms\n",
      "Speed: 3.2ms preprocess, 21.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 19.6ms\n",
      "Speed: 2.2ms preprocess, 19.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 11.0ms\n",
      "Speed: 1.3ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 11.0ms\n",
      "Speed: 1.3ms preprocess, 11.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 10.6ms\n",
      "Speed: 1.4ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 10.4ms\n",
      "Speed: 1.8ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 13.0ms\n",
      "Speed: 1.4ms preprocess, 13.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 10.2ms\n",
      "Speed: 1.3ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 8 cars, 10.6ms\n",
      "Speed: 1.4ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 8 cars, 10.6ms\n",
      "Speed: 1.3ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 7 cars, 10.5ms\n",
      "Speed: 1.4ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 6 cars, 11.8ms\n",
      "Speed: 1.7ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 10.3ms\n",
      "Speed: 1.5ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 7 cars, 10.5ms\n",
      "Speed: 1.4ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 11.2ms\n",
      "Speed: 1.4ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 11.4ms\n",
      "Speed: 1.3ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 11.1ms\n",
      "Speed: 1.3ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 8 cars, 10.7ms\n",
      "Speed: 1.5ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 7 cars, 1 train, 10.8ms\n",
      "Speed: 1.8ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 6 cars, 11.0ms\n",
      "Speed: 1.3ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 11.3ms\n",
      "Speed: 1.4ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 6 cars, 10.9ms\n",
      "Speed: 1.4ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 10.7ms\n",
      "Speed: 1.3ms preprocess, 10.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 10.6ms\n",
      "Speed: 1.2ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 10.7ms\n",
      "Speed: 1.4ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 11.2ms\n",
      "Speed: 1.3ms preprocess, 11.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 12.8ms\n",
      "Speed: 1.3ms preprocess, 12.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 10.6ms\n",
      "Speed: 1.5ms preprocess, 10.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 12.2ms\n",
      "Speed: 1.7ms preprocess, 12.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 10.5ms\n",
      "Speed: 2.1ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 10.8ms\n",
      "Speed: 2.4ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=10, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 10, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 14.6ms\n",
      "Speed: 1.2ms preprocess, 14.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=10, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 10, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 12.1ms\n",
      "Speed: 2.2ms preprocess, 12.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=10, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 10, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 6 cars, 10.6ms\n",
      "Speed: 1.3ms preprocess, 10.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=10, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 10, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 12.1ms\n",
      "Speed: 1.4ms preprocess, 12.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=10, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 10, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 10.7ms\n",
      "Speed: 1.5ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=10, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 10, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 12.8ms\n",
      "Speed: 1.3ms preprocess, 12.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=10, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 10, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 10.5ms\n",
      "Speed: 1.4ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=10, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 10, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 11.4ms\n",
      "Speed: 1.3ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 11.1ms\n",
      "Speed: 1.4ms preprocess, 11.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 13.2ms\n",
      "Speed: 1.7ms preprocess, 13.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 13.8ms\n",
      "Speed: 1.4ms preprocess, 13.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 12.8ms\n",
      "Speed: 1.4ms preprocess, 12.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 12.6ms\n",
      "Speed: 1.4ms preprocess, 12.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 4 cars, 12.9ms\n",
      "Speed: 1.4ms preprocess, 12.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 4 cars, 12.9ms\n",
      "Speed: 1.4ms preprocess, 12.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 5 cars, 13.0ms\n",
      "Speed: 1.4ms preprocess, 13.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 11.6ms\n",
      "Speed: 1.4ms preprocess, 11.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 10.7ms\n",
      "Speed: 2.3ms preprocess, 10.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 12.6ms\n",
      "Speed: 1.4ms preprocess, 12.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 12.6ms\n",
      "Speed: 1.5ms preprocess, 12.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 10.6ms\n",
      "Speed: 1.4ms preprocess, 10.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 13.3ms\n",
      "Speed: 1.5ms preprocess, 13.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 11.5ms\n",
      "Speed: 1.4ms preprocess, 11.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 10.8ms\n",
      "Speed: 2.4ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics.solutions import ObjectCounter\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "assert cap.isOpened(), 'Error reading video file'   # 파일 열리지 않으면 경고\n",
    "\n",
    "region_points = [(20, 400), (1080, 400)]   # 라인수\n",
    "fps = cap.get(cv2.CAP_PROP_FPS) # 동영상 FPS(Frame Per Second)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))      # 1280\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))    # 720\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "# 물체 인식 핵심 객체\n",
    "counter = solutions.ObjectCounter(\n",
    "    show = True,              # 처리중 화면에 디스플레이\n",
    "    region = region_points,   # 라인위치\n",
    "    model = './yolo11n.pt',   # YOLO 모델\n",
    "    # classes = [0, 2],\n",
    "    # tracker = 'botsort.yaml',\n",
    ")\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "\n",
    "    results = counter(frame)\n",
    "    out.write(results.plot_im)    # 여기 차이\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
